{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition du Problème\n",
    "\n",
    "Il est question dans ce modèle d'apprentissage de predire si l'objet rencontré par un sonar sous marin actif est une \n",
    "mine ou une Roche.<br> \n",
    "En effet, le sonar va envoyer dans l'eau une energie élètrique qui sera transformée en onde sonore. Si cette onde \n",
    "rencontre un objet, elle rebondit puis captée par le sonar qui va la retransformée en energie élètrique(Signal élèctrique).<br> \n",
    "Nous obtenons donc des observations correspondantes à l'intensité du signal éléctrique réçu dans une bande de frequence \n",
    "sonore particulière. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquisition des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0200</th>\n",
       "      <th>0.0371</th>\n",
       "      <th>0.0428</th>\n",
       "      <th>0.0207</th>\n",
       "      <th>0.0954</th>\n",
       "      <th>0.0986</th>\n",
       "      <th>0.1539</th>\n",
       "      <th>0.1601</th>\n",
       "      <th>0.3109</th>\n",
       "      <th>0.2111</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0027</th>\n",
       "      <th>0.0065</th>\n",
       "      <th>0.0159</th>\n",
       "      <th>0.0072</th>\n",
       "      <th>0.0167</th>\n",
       "      <th>0.0180</th>\n",
       "      <th>0.0084</th>\n",
       "      <th>0.0090</th>\n",
       "      <th>0.0032</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109  \\\n",
       "0  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "1  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "2  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "3  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "4  0.0286  0.0453  0.0277  0.0174  0.0384  0.0990  0.1201  0.1833  0.2105   \n",
       "\n",
       "   0.2111 ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084  0.0090  \\\n",
       "0  0.2872 ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049  0.0052   \n",
       "1  0.6194 ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164  0.0095   \n",
       "2  0.1264 ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044  0.0040   \n",
       "3  0.4459 ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048  0.0107   \n",
       "4  0.3039 ...  0.0045  0.0014  0.0038  0.0013  0.0089  0.0057  0.0027  0.0051   \n",
       "\n",
       "   0.0032  R  \n",
       "0  0.0044  R  \n",
       "1  0.0078  R  \n",
       "2  0.0117  R  \n",
       "3  0.0094  R  \n",
       "4  0.0062  R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations = pd.read_csv(\"C:/Users/Andreas/PycharmProjects/SONAR_ONDE/datas/sonar.all-data.csv\")\n",
    "observations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le dataset n'a pas de nom de colonne. Rectifions cela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>...</th>\n",
       "      <th>F52</th>\n",
       "      <th>F53</th>\n",
       "      <th>F54</th>\n",
       "      <th>F55</th>\n",
       "      <th>F56</th>\n",
       "      <th>F57</th>\n",
       "      <th>F58</th>\n",
       "      <th>F59</th>\n",
       "      <th>F60</th>\n",
       "      <th>OBJET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       F1      F2      F3      F4      F5      F6      F7      F8      F9  \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "      F10  ...       F52     F53     F54     F55     F56     F57     F58  \\\n",
       "0  0.2111  ...    0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...    0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...    0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...    0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...    0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "      F59     F60  OBJET  \n",
       "0  0.0090  0.0032      R  \n",
       "1  0.0052  0.0044      R  \n",
       "2  0.0095  0.0078      R  \n",
       "3  0.0040  0.0117      R  \n",
       "4  0.0107  0.0094      R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations = pd.read_csv(\"C:/Users/Andreas/PycharmProjects/SONAR_ONDE/datas/sonar.all-data.csv\", names=[\"F1\", \"F2\", \"F3\"\n",
    "                , \"F4\", \"F5\", \"F6\", \"F7\", \"F8\", \"F9\", \"F10\", \"F11\", \"F12\", \"F13\", \"F14\", \"F15\", \"F16\", \"F17\", \"F18\", \"F19\"\n",
    "                , \"F20\", \"F21\", \"F22\", \"F23\", \"F24\", \"F25\", \"F26\", \"F27\", \"F28\", \"F29\", \"F30\", \"F31\", \"F32\", \"F33\", \"F34\"\n",
    "                , \"F35\", \"F36\", \"F37\", \"F38\", \"F39\", \"F40\", \"F41\", \"F42\", \"F43\", \"F44\", \"F45\", \"F46\", \"F47\", \"F48\", \"F49\"\n",
    "                , \"F50\", \"F51\", \"F52\", \"F53\", \"F54\", \"F55\", \"F56\", \"F57\", \"F58\", \"F59\", \"F60\", \"OBJET\"])\n",
    "\n",
    "observations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 61 columns):\n",
      "F1       208 non-null float64\n",
      "F2       208 non-null float64\n",
      "F3       208 non-null float64\n",
      "F4       208 non-null float64\n",
      "F5       208 non-null float64\n",
      "F6       208 non-null float64\n",
      "F7       208 non-null float64\n",
      "F8       208 non-null float64\n",
      "F9       208 non-null float64\n",
      "F10      208 non-null float64\n",
      "F11      208 non-null float64\n",
      "F12      208 non-null float64\n",
      "F13      208 non-null float64\n",
      "F14      208 non-null float64\n",
      "F15      208 non-null float64\n",
      "F16      208 non-null float64\n",
      "F17      208 non-null float64\n",
      "F18      208 non-null float64\n",
      "F19      208 non-null float64\n",
      "F20      208 non-null float64\n",
      "F21      208 non-null float64\n",
      "F22      208 non-null float64\n",
      "F23      208 non-null float64\n",
      "F24      208 non-null float64\n",
      "F25      208 non-null float64\n",
      "F26      208 non-null float64\n",
      "F27      208 non-null float64\n",
      "F28      208 non-null float64\n",
      "F29      208 non-null float64\n",
      "F30      208 non-null float64\n",
      "F31      208 non-null float64\n",
      "F32      208 non-null float64\n",
      "F33      208 non-null float64\n",
      "F34      208 non-null float64\n",
      "F35      208 non-null float64\n",
      "F36      208 non-null float64\n",
      "F37      208 non-null float64\n",
      "F38      208 non-null float64\n",
      "F39      208 non-null float64\n",
      "F40      208 non-null float64\n",
      "F41      208 non-null float64\n",
      "F42      208 non-null float64\n",
      "F43      208 non-null float64\n",
      "F44      208 non-null float64\n",
      "F45      208 non-null float64\n",
      "F46      208 non-null float64\n",
      "F47      208 non-null float64\n",
      "F48      208 non-null float64\n",
      "F49      208 non-null float64\n",
      "F50      208 non-null float64\n",
      "F51      208 non-null float64\n",
      "F52      208 non-null float64\n",
      "F53      208 non-null float64\n",
      "F54      208 non-null float64\n",
      "F55      208 non-null float64\n",
      "F56      208 non-null float64\n",
      "F57      208 non-null float64\n",
      "F58      208 non-null float64\n",
      "F59      208 non-null float64\n",
      "F60      208 non-null float64\n",
      "OBJET    208 non-null object\n",
      "dtypes: float64(60), object(1)\n",
      "memory usage: 99.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#Données manquantes?\n",
    "observations.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation<br> \n",
    "Nous n'observons aucune donnée manquante et toutes nos données sont des valeurs numériques continues à l'exception de la valeur cible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>...</th>\n",
       "      <th>F51</th>\n",
       "      <th>F52</th>\n",
       "      <th>F53</th>\n",
       "      <th>F54</th>\n",
       "      <th>F55</th>\n",
       "      <th>F56</th>\n",
       "      <th>F57</th>\n",
       "      <th>F58</th>\n",
       "      <th>F59</th>\n",
       "      <th>F60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.104570</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>0.178003</td>\n",
       "      <td>0.208259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.006507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>0.059105</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.134416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.080425</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.111275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.044050</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.092150</td>\n",
       "      <td>0.106950</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.152250</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035550</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.057950</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.233425</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.008525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               F1          F2          F3          F4          F5          F6  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.029164    0.038437    0.043832    0.053892    0.075202    0.104570   \n",
       "std      0.022991    0.032960    0.038428    0.046528    0.055552    0.059105   \n",
       "min      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n",
       "25%      0.013350    0.016450    0.018950    0.024375    0.038050    0.067025   \n",
       "50%      0.022800    0.030800    0.034300    0.044050    0.062500    0.092150   \n",
       "75%      0.035550    0.047950    0.057950    0.064500    0.100275    0.134125   \n",
       "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n",
       "\n",
       "               F7          F8          F9         F10     ...             F51  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000     ...      208.000000   \n",
       "mean     0.121747    0.134799    0.178003    0.208259     ...        0.016069   \n",
       "std      0.061788    0.085152    0.118387    0.134416     ...        0.012008   \n",
       "min      0.003300    0.005500    0.007500    0.011300     ...        0.000000   \n",
       "25%      0.080900    0.080425    0.097025    0.111275     ...        0.008425   \n",
       "50%      0.106950    0.112100    0.152250    0.182400     ...        0.013900   \n",
       "75%      0.154000    0.169600    0.233425    0.268700     ...        0.020825   \n",
       "max      0.372900    0.459000    0.682800    0.710600     ...        0.100400   \n",
       "\n",
       "              F52         F53         F54         F55         F56         F57  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.013420    0.010709    0.010941    0.009290    0.008222    0.007820   \n",
       "std      0.009634    0.007060    0.007301    0.007088    0.005736    0.005785   \n",
       "min      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n",
       "25%      0.007275    0.005075    0.005375    0.004150    0.004400    0.003700   \n",
       "50%      0.011400    0.009550    0.009300    0.007500    0.006850    0.005950   \n",
       "75%      0.016725    0.014900    0.014500    0.012100    0.010575    0.010425   \n",
       "max      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n",
       "\n",
       "              F58         F59         F60  \n",
       "count  208.000000  208.000000  208.000000  \n",
       "mean     0.007949    0.007941    0.006507  \n",
       "std      0.006470    0.006181    0.005031  \n",
       "min      0.000300    0.000100    0.000600  \n",
       "25%      0.003600    0.003675    0.003100  \n",
       "50%      0.005800    0.006400    0.005300  \n",
       "75%      0.010350    0.010325    0.008525  \n",
       "max      0.044000    0.036400    0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous observons que nous que pour chacune de nos valeurs, une moyenne qui tend vers zero et un écart type tendant vers 1.\n",
    "Nous pouvons dire que nos données sont normalisées. Ce qui rend notre jeu d'obervation propice à l'utilisation des <b> ANN(Artificial Neural Network).<b> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysons notre variable de categorisation <b>(OBJET)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "observations.OBJET.value_counts().plot.bar()\n",
    "plt.xlabel('Objet')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous remarquons la légère difference existante entre ces deux valeurs. Par conséquent nous pouvons l'utiliser(jeu observations) sans craindre d'impacter notre modèle d'apprentissage.\n",
    "Nous allons à présent verifier l'existence des valeurs extrêmes qui éventuellement peuvent conduire à des mauvaises \n",
    "prédictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = observations.iloc[:,0:60].values\n",
    "\n",
    "Y = observations.iloc[:,-1].values\n",
    "#X = observations[observations.columns[0:60]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformons la variable categorielle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#La feature 'OBJET' represente notre varaible expliqéé et est de type categorielle, On va donc l'encoder entierement \n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "Y = encoder.transform(Y)\n",
    "#Une fois l'encodage entier effectué, tranformons notre variable en vectuer binaire afin d'indentifier les etiquettes\n",
    "oneHot_encoder = OneHotEncoder()\n",
    "Y = oneHot_encoder.fit_transform(Y.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Création des jeux d'apprentissage et de test\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "Y_validation[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase d'apprentissage\n",
    "\n",
    "### Configuration du réseau de neuronnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5455465\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Parametrage de notre réseaux de neurones\n",
    "\n",
    "#Variables correspondantes aux valeurs de neurones d'entrée\n",
    "neurones_entrees = tf.placeholder(tf.float32, [None,60])\n",
    "\n",
    "#Variables de sortie\n",
    "neurones_sorties = tf.placeholder(tf.float32, [None,2])\n",
    "\n",
    "#Poids neurones de la couche cachée\n",
    "poids = {\n",
    "    #Poids neurones d'entrées vers la couche cachée\n",
    "    'couche_entree_vers_cachee':tf.Variable(tf.random_normal([60,24]), tf.float32),\n",
    "    #Poids neurones cochée vers couche de sortie\n",
    "    'couche_cachee_vers_sortie':tf.Variable(tf.random_normal([24,2]), tf.float32)\n",
    "}\n",
    "biais = {\n",
    "    'biais_couche_entree': tf.Variable(tf.zeros([24]), tf.float32),\n",
    "    'biais_couche_cachee': tf.Variable(tf.zeros([2]), tf.float32)\n",
    "}\n",
    "\n",
    "#Calcul de la somme ponderee\n",
    "def activation_neuronnes(neurones_entrees,poids,biais):\n",
    "    #Activation de la couche cachée\n",
    "    sommeponderee = tf.sigmoid(tf.matmul(neurones_entrees,poids['couche_entree_vers_cachee']) + biais['biais_couche_entree'])\n",
    "    activation = tf.sigmoid(tf.matmul(sommeponderee,poids['couche_cachee_vers_sortie'])+biais['biais_couche_cachee'])\n",
    "    return activation\n",
    "activation = activation_neuronnes(neurones_entrees,poids,biais)\n",
    "\n",
    "#Fonction d'erreur\n",
    "error = tf.reduce_sum(tf.pow(neurones_sorties-activation,2))\n",
    "\n",
    "#Descente de gradient\n",
    "optimisation = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(error)\n",
    "\n",
    "#Apprentissage de reseau de neuronnes\n",
    "\n",
    "#Initialaisation des variables\n",
    "init = tf.global_variables_initializer()\n",
    "session = tf.Session()\n",
    "session.run(init)\n",
    "\n",
    "EPOCHS = 1500\n",
    "Graphics_MSE = []\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    session.run(optimisation, feed_dict={neurones_entrees:X_train,neurones_sorties:Y_train })\n",
    "    \n",
    "    MSE = session.run(error, feed_dict={neurones_entrees:X_train,neurones_sorties:Y_train})\n",
    "    Graphics_MSE.append(MSE)\n",
    "    \n",
    "print(MSE)\n",
    "plt.plot(Graphics_MSE)\n",
    "plt.xlabel('EPOCHS')\n",
    "plt.ylabel('MSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculons la précision sur les données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Attendue: [0] classe réalisée:[0]\n",
      "Classification Attendue: [1] classe réalisée:[1]\n",
      "Classification Attendue: [1] classe réalisée:[1]\n",
      "Classification Attendue: [1] classe réalisée:[1]\n",
      "Classification Attendue: [0] classe réalisée:[0]\n",
      "Classification Attendue: [1] classe réalisée:[0]\n",
      "Classification Attendue: [0] classe réalisée:[0]\n",
      "Classification Attendue: [0] classe réalisée:[0]\n",
      "Classification Attendue: [1] classe réalisée:[1]\n",
      "Classification Attendue: [0] classe réalisée:[0]\n",
      "Classification Attendue: [0] classe réalisée:[0]\n",
      "Classification Attendue: [1] classe réalisée:[1]\n",
      "Classification Attendue: [0] classe réalisée:[0]\n",
      "Classification Attendue: [0] classe réalisée:[0]\n",
      "Classification Attendue: [0] classe réalisée:[0]\n",
      "Classification Attendue: [0] classe réalisée:[0]\n",
      "Classification Attendue: [0] classe réalisée:[0]\n",
      "Classification Attendue: [0] classe réalisée:[0]\n",
      "Classification Attendue: [1] classe réalisée:[0]\n",
      "Classification Attendue: [1] classe réalisée:[1]\n",
      "Classification Attendue: [0] classe réalisée:[0]\n",
      "Classification Attendue: [0] classe réalisée:[0]\n",
      "Classification Attendue: [0] classe réalisée:[0]\n",
      "Classification Attendue: [0] classe réalisée:[1]\n",
      "Classification Attendue: [1] classe réalisée:[1]\n",
      "Classification Attendue: [1] classe réalisée:[1]\n",
      "Classification Attendue: [1] classe réalisée:[1]\n",
      "Classification Attendue: [1] classe réalisée:[0]\n",
      "Classification Attendue: [0] classe réalisée:[0]\n",
      "Classification Attendue: [0] classe réalisée:[0]\n",
      "Classification Attendue: [0] classe réalisée:[0]\n",
      "Classification Attendue: [1] classe réalisée:[1]\n",
      "Classification Attendue: [1] classe réalisée:[1]\n",
      "Classification Attendue: [0] classe réalisée:[0]\n",
      "Classification Attendue: [0] classe réalisée:[0]\n",
      "Classification Attendue: [0] classe réalisée:[0]\n",
      "Classification Attendue: [0] classe réalisée:[0]\n",
      "Classification Attendue: [0] classe réalisée:[0]\n",
      "Classification Attendue: [1] classe réalisée:[1]\n",
      "Classification Attendue: [0] classe réalisée:[0]\n",
      "Classification Attendue: [1] classe réalisée:[1]\n",
      "Classification Attendue: [0] classe réalisée:[1]\n",
      "Precision sur mes données de test:0.8809523809523809\n"
     ]
    }
   ],
   "source": [
    "#Calcul de la precision de notre modele sur les données de test\n",
    "\n",
    "#On recupère l'index de classification la plus haute\n",
    "classifications = tf.argmax(activation,1)\n",
    "\n",
    "#On compare les classifications réalisées avec celles attendues\n",
    "comparaison_classification = tf.equal(classifications, tf.argmax(neurones_sorties,1))\n",
    "\n",
    "#On calcul la moyenne des bonnes classifications\n",
    "#Sachant que la fonction tf.equal renvoie des booleans, nous allons caster ce output\n",
    "formule_precision = tf.reduce_mean(tf.cast(comparaison_classification, tf.float32))\n",
    "\n",
    "#Debut de notre algorithme\n",
    "#Nous allons calculer le pourcentage de bonne clasifications\n",
    "nb_classifications = 0\n",
    "nb_bonne_classification = 0\n",
    "\n",
    "for i in range(X_validation.shape[0]):\n",
    "    #On reformate chaque donnée d'entrée et de sortie\n",
    "    donneesolar =  X_validation[i].reshape(1,60)\n",
    "    classificationAttendue = Y_validation[i].reshape(1,2)\n",
    "    \n",
    "    #On recupère l'index de la bonne classification\n",
    "    index_bonne_classification = session.run(classifications, feed_dict={neurones_entrees:donneesolar})\n",
    "    \n",
    "    #On calcule la moyenne de la classification\n",
    "    moyenne_classification = session.run(formule_precision, feed_dict={neurones_entrees:donneesolar, \n",
    "                                                                       neurones_sorties:classificationAttendue})\n",
    "    \n",
    "    #On affiche nos résultats\n",
    "    classe_attendue = tf.argmax(classificationAttendue,1)\n",
    "    index_classe_attendue = session.run(classe_attendue, feed_dict={neurones_sorties:classificationAttendue})\n",
    "    \n",
    "    print(\"Classification Attendue: \"+str(index_classe_attendue)+\" classe réalisée:\"+str(index_bonne_classification))\n",
    "    nb_classifications = nb_classifications+1\n",
    "    \n",
    "    if (moyenne_classification*100 == 100):\n",
    "            nb_bonne_classification = nb_bonne_classification+1\n",
    "            \n",
    "print('Precision sur mes données de test:'+str(nb_bonne_classification/nb_classifications))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision sur mes données d'apprentissage: 0.9939759036144579\n"
     ]
    }
   ],
   "source": [
    "#Precison sur mes données d'apprentissage\n",
    "nb_classification = 0\n",
    "nb_bonnes_classifications = 0\n",
    "for i in range(X_train.shape[0]):\n",
    "    #On reformate chaque donnée d'entrée et de sortie\n",
    "    donneesolaire =  X_train[i].reshape(1,60)\n",
    "    classificationAttendu = Y_train[i].reshape(1,2)\n",
    "    \n",
    "    #On recupère l'index de la bonne classification\n",
    "    index_bonn_classification = session.run(classifications, feed_dict={neurones_entrees:donneesolaire})\n",
    "    \n",
    "    #On calcule la moyenne de la classification\n",
    "    mean_classification = session.run(formule_precision, feed_dict={neurones_entrees:donneesolaire, \n",
    "                                                                       neurones_sorties:classificationAttendu})\n",
    "    nb_classification = nb_classification+1\n",
    "    #On affiche nos résultats\n",
    "    if (mean_classification*100 == 100):\n",
    "            nb_bonnes_classifications = nb_bonnes_classifications+1\n",
    "            \n",
    "print('Precision sur mes données d\\'apprentissage: '+str(nb_bonnes_classifications/nb_classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
